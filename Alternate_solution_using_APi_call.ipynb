{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVSsm02P8Yq+g1RMCQZUhk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nakshith21/AI-developer-task-ADmybrand-india/blob/main/Alternate_solution_using_APi_call.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "id": "-wfs-6-C-oU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai as ai\n",
        "\n",
        "ai.api_key = 'sk-somekeygoeshere' # replace with your key from earlier"
      ],
      "metadata": {
        "id": "dNUDMbYsTWzD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai as ai\n",
        "\n",
        "# Get the key from an environment variable on the machine it is running on\n",
        "ai.api_key = os.environ.get(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "Vxj0evh3TbPk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_gpt3_response(user_text, print_output=False):\n",
        "    \"\"\"\n",
        "    Query OpenAI GPT-3 for the specific key and get back a response\n",
        "    :type user_text: str the user's text to query for\n",
        "    :type print_output: boolean whether or not to print the raw output JSON\n",
        "    \"\"\"\n",
        "    completions = ai.Completion.create(\n",
        "        engine='text-davinci-003',  # Determines the quality, speed, and cost.\n",
        "        temperature=0.5,            # Level of creativity in the response\n",
        "        prompt=user_text,           # What the user typed in\n",
        "        max_tokens=100,             # Maximum tokens in the prompt AND response\n",
        "        n=1,                        # The number of completions to generate\n",
        "        stop=None,                  # An optional setting to control response generation\n",
        "    )\n",
        "\n",
        "    # Displaying the output can be helpful if things go wrong\n",
        "    if print_output:\n",
        "        print(completions)\n",
        "\n",
        "    # Return the first choice's text\n",
        "    return completions.choices[0].text"
      ],
      "metadata": {
        "id": "Z3chR246TgP8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = ai.Model.list()\n",
        "\n",
        "for model in models.data:\n",
        "    print(model.id)"
      ],
      "metadata": {
        "id": "C9_V0aRA-rm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    prompt = ('a haunted house', 'an unexpected visitor', 'a time travel adventure')\n",
        "    response = generate_gpt3_response(prompt)\n",
        "    \n",
        "    print(response)"
      ],
      "metadata": {
        "id": "W1Ds6Ifn-tPe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}